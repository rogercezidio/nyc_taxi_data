{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8f79a83-913d-45e3-93b1-9ba7ef510f69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F, types as T\n",
    "from datetime import datetime\n",
    "from functools   import reduce\n",
    "from helpers import SILVER, GOLD, TAXI_TYPES, table_exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "662a2189-f65d-4f25-84b8-43f60f6a0af2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Criação de dimensão dim_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79369e65-a3ae-487e-923b-48bc5b968e42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {GOLD.TBL_DIM_DATE} (\n",
    "    date_id      INT    COMMENT 'yyyymmdd',\n",
    "    date         DATE,\n",
    "    year         INT,\n",
    "    month        INT,\n",
    "    day          INT,\n",
    "    day_of_week  INT,          \n",
    "    is_weekend   BOOLEAN,\n",
    "    quarter      INT\n",
    ") USING DELTA\n",
    "\"\"\")\n",
    "\n",
    "dates = (\n",
    "    spark.sql(\"\"\"\n",
    "        SELECT explode(\n",
    "                 sequence( to_date('2023-01-01')\n",
    "                         , to_date('2023-12-31')\n",
    "                         , interval 1 day)\n",
    "               ) AS date\n",
    "    \"\"\")\n",
    "    .withColumn(\"date_id\",     F.date_format(\"date\", \"yyyyMMdd\").cast(\"int\"))\n",
    "    .withColumn(\"year\",        F.year(\"date\"))\n",
    "    .withColumn(\"month\",       F.month(\"date\"))\n",
    "    .withColumn(\"day\",         F.dayofmonth(\"date\"))\n",
    "    .withColumn(\"day_of_week\", F.dayofweek(\"date\"))     \n",
    "    .withColumn(\"is_weekend\",  F.col(\"day_of_week\").isin(1,7))\n",
    "    .withColumn(\"quarter\",     F.quarter(\"date\"))\n",
    ")\n",
    "\n",
    "\n",
    "(dates.write\n",
    "      .format(\"delta\")\n",
    "      .mode(\"overwrite\")         \n",
    "      .option(\"overwriteSchema\", \"true\")\n",
    "      .saveAsTable(GOLD.TBL_DIM_DATE))       \n",
    "\n",
    "rows = spark.table(GOLD.TBL_DIM_DATE).count()\n",
    "print(f\"dim_date populada com {rows:,} linhas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "971c1452-18e4-4570-bbad-0d47335d0956",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Criação de tabela fato: fact_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9409dd2f-eb0d-4265-aaf3-bf468cbc8a27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "agg_dfs = []\n",
    "for tt in TAXI_TYPES:\n",
    "    src_tbl = f\"{SILVER.SCHEMA}.{tt}_tripdata_silver\"\n",
    "    if not spark.catalog.tableExists(src_tbl):\n",
    "        print(f\"Silver ausente → {tt}\")\n",
    "        continue\n",
    "\n",
    "    df = spark.table(src_tbl)\n",
    "\n",
    "    pickup_col  = next(c for c in df.columns if c.endswith(\"pickup_datetime\"))\n",
    "    dropoff_col = next(c for c in df.columns if c.endswith(\"dropoff_datetime\"))\n",
    "\n",
    "    df = (df\n",
    "          .withColumnRenamed(pickup_col,  \"pickup_ts\")\n",
    "          .withColumnRenamed(dropoff_col, \"dropoff_ts\")\n",
    "          .withColumn(\"pickup_date_id\",  F.date_format(\"pickup_ts\", \"yyyyMMdd\").cast(\"int\"))\n",
    "          .withColumn(\"pickup_time_id\",  (F.hour(\"pickup_ts\")*100 + F.minute(\"pickup_ts\")).cast(\"int\"))\n",
    "          .withColumn(\"taxi_type\",       F.lit(tt))\n",
    "          .withColumn(\n",
    "            \"duration_min\",\n",
    "            F.expr(\"timestampdiff(SECOND, pickup_ts, dropoff_ts)\") / 60.0\n",
    "           )\n",
    "          .withColumn(\"distance_mi\",     F.col(\"trip_distance\"))\n",
    "          .withColumn(\"fare\",            F.col(\"total_amount\"))\n",
    "    )\n",
    "\n",
    "    agg = (df.groupBy(\"taxi_type\",\"pickup_date_id\",\"pickup_time_id\")\n",
    "              .agg(\n",
    "                  F.count(\"*\").alias(\"num_trips\"),\n",
    "                  F.sum(\"passenger_count\").alias(\"total_passengers\"),\n",
    "                  F.sum(\"fare\").alias(\"total_revenue\"),\n",
    "                  F.sum(\"distance_mi\").alias(\"distance_mi\"),\n",
    "                  F.sum(\"duration_min\").alias(\"total_duration\"))\n",
    "              .withColumn(\"avg_fare\",     F.round(F.col(\"total_revenue\")/F.col(\"num_trips\"),2))\n",
    "              .withColumn(\"avg_distance\", F.round(F.col(\"distance_mi\")/F.col(\"num_trips\"),2))\n",
    "              .withColumn(\"avg_duration\", F.round(F.col(\"total_duration\")/F.col(\"num_trips\"),2))\n",
    "              .withColumn(\"revenue_mi\",   F.round(F.col(\"total_revenue\")/F.col(\"distance_mi\"),2))\n",
    "              .withColumn(\"load_factor\",  F.round(F.col(\"total_passengers\")/F.col(\"num_trips\"),2))\n",
    "          )\n",
    "    agg_dfs.append(agg)\n",
    "\n",
    "all_agg = reduce(lambda a,b: a.unionByName(b, allowMissingColumns=True), agg_dfs)\n",
    "\n",
    "tgt_tbl = f\"{GOLD.SCHEMA}.fact_trips\"\n",
    "\n",
    "(all_agg.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")            \n",
    "    .partitionBy(\"pickup_date_id\") \n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .option(\"delta.feature.checkConstraints\",\"supported\")\n",
    "    .saveAsTable(tgt_tbl) \n",
    ")\n",
    "\n",
    "print(\"Gold fact_trips criada —\",\n",
    "      spark.table(tgt_tbl).count(), \"linhas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "646e3083-5a8a-477d-bb12-f9c6d0ded53b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6965736245755702,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "04_etl_gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
