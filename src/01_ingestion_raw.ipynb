{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14d08431-ab62-4755-8bf2-b2e93b0fb4a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "b9409a72-8e6e-471e-948a-390c576bd015",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "232985cd-b5be-49f9-9319-db975fd9ffdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from helpers import RAW, table_exists, CATALOG, BUCKET_BASE, TAG, _root, CREDS_NAME, TAXI_TYPES\n",
    "import os, requests, tempfile, pathlib, shutil, sys\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98173414-c31b-4dfd-8cf4-0b7b598442d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### üîß Cria√ß√£o da estrutura base do Data Lakehouse\n",
    "\n",
    "Este trecho cria a estrutura inicial no Unity Catalog:\n",
    "\n",
    "- Define o **cat√°logo** e os **schemas** para as camadas `raw`, `bronze`, `quarentine`, `silver` e `gold`;\n",
    "- Cria **volumes UC** e **volumes externos** para armazenar os dados em cada camada.\n",
    "\n",
    "üéØ **Objetivo**: organizar os dados por est√°gio de processamento e garantir governan√ßa, separa√ß√£o l√≥gica e controle de acesso adequado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad2649c4-f155-4ae0-b02d-23ad98b0e9c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.getActiveSession()\n",
    "\n",
    "# 1. root\n",
    "ddl_root = f\"\"\"\n",
    "CREATE EXTERNAL LOCATION IF NOT EXISTS {CATALOG}_root\n",
    "  URL '{BUCKET_BASE}'\n",
    "  WITH (STORAGE CREDENTIAL `{CREDS_NAME}`);\n",
    "\"\"\"\n",
    "\n",
    "# 2. Cat√°logo e SCHEMAs\n",
    "ddl_catalog = f\"\"\"\n",
    "CREATE CATALOG IF NOT EXISTS {CATALOG}\n",
    "  MANAGED LOCATION '{BUCKET_BASE}/uc_root';\n",
    "\"\"\"\n",
    "\n",
    "layers = [\"raw\", \"bronze\", \"quarentine\", \"silver\", \"gold\"]\n",
    "ddl_schemas = \"\\n\".join(\n",
    "    f\"\"\"\n",
    "    CREATE SCHEMA IF NOT EXISTS {CATALOG}.{layer}\n",
    "      MANAGED LOCATION '{BUCKET_BASE}/{layer}/_tables/';\n",
    "    \"\"\".strip()\n",
    "    for layer in layers\n",
    ")\n",
    "\n",
    "#3. Volumes UC (RAW) + External Volumes\n",
    "ddl_volumes = f\"\"\"\n",
    "-- RAW ‚îÄ‚îÄ Volume UC (DBFS)\n",
    "CREATE VOLUME IF NOT EXISTS {CATALOG}.raw.{TAG}_ingest\n",
    "COMMENT 'Landing zone RAW {TAG.upper()}';\n",
    "\n",
    "\"\"\" + \"\\n\".join(\n",
    "    f\"\"\"\n",
    "    -- {layer.upper()} ‚îÄ‚îÄ external volume\n",
    "    CREATE EXTERNAL VOLUME IF NOT EXISTS {CATALOG}.{layer}.{TAG}_{layer}\n",
    "    LOCATION '{_root(layer, \"volumes\")}'\n",
    "    COMMENT 'Camada {layer} ‚Äì dados {TAG.upper()}';\n",
    "    \"\"\".strip()\n",
    "    for layer in [\"bronze\", \"quarentine\", \"silver\", \"gold\"]\n",
    ")\n",
    "\n",
    "for stmt in [ddl_root, ddl_catalog, ddl_schemas, ddl_volumes]:\n",
    "    for sql in filter(None, (s.strip() for s in stmt.split(\";\"))):\n",
    "        spark.sql(sql)         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64d4f6e3-1c9a-47b8-830d-2cd0563a8f59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### üì• Download e armazenamento dos arquivos Parquet\n",
    "\n",
    "Este trecho realiza o **download dos arquivos Parquet** diretamente da fonte oficial (NYC Taxi Data) e os **salva no volume UC da camada `raw`**, organizando por tipo de t√°xi, ano e m√™s.\n",
    "Aqui s√£o coletados os dados de 2023 em diante, pois registros podem ser enviados posteriormente, a limpeza e verifica√ß√£o ser√° feita nas camadas bronze/silver.\n",
    "\n",
    "üéØ **Objetivo**: garantir a ingest√£o dos dados brutos no Data Lake, mantendo uma estrutura de particionamento que facilita o processamento posterior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72639bf4-0945-41cd-823e-8c65695ecf41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "def download_one(url: str, dst: str) -> bool:\n",
    "\n",
    "    try:\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as tmp:\n",
    "            with requests.get(url, stream=True, timeout=180) as r:\n",
    "                if r.status_code in (403, 404):\n",
    "                    print(f\"{r.status_code} ‚Äì n√£o dispon√≠vel\")\n",
    "                    return False\n",
    "                r.raise_for_status()\n",
    "                for blk in r.iter_content(RAW.CHUNK):\n",
    "                    tmp.write(blk)\n",
    "            local_tmp = tmp.name\n",
    "\n",
    "        dbutils.fs.cp(\"file:\" + local_tmp, dst)\n",
    "        print(\"Arquivo salvo em:\", dst)\n",
    "        return True\n",
    "\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(\"erro HTTP:\", e)\n",
    "        return False\n",
    "    finally:\n",
    "        try:\n",
    "            os.remove(local_tmp)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "\n",
    "total = 0\n",
    "for tt in TAXI_TYPES:\n",
    "    for yy in RAW.YEARS:\n",
    "        for mm in RAW.MONTHS:\n",
    "            fname = f\"{tt}_tripdata_{yy}-{mm}.parquet\"\n",
    "            url   = f\"{RAW.BASE_URL}/{fname}\"\n",
    "            dst   = (f\"{RAW.DEST_ROOT}/\"\n",
    "                     f\"taxi_type={tt}/year={yy}/month={mm}/{fname}\")\n",
    "\n",
    "            sys.stdout.write(f\"{tt}/{yy}-{mm}: \")\n",
    "            sys.stdout.flush()\n",
    "            if download_one(url, dst):\n",
    "                total += 1\n",
    "\n",
    "print(f\"Download conclu√≠do ‚Äì {total:,} arquivos novos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1515004c-9416-4dad-a119-0b7c1f64491f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6965736245755664,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "01_ingestion_raw",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
