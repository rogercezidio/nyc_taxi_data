{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17828d18-442f-4fad-8098-08045bf2b837",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b9c268b-7bca-4ca3-b978-6a03b918dd99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Enables autoreload; learn more at https://docs.databricks.com/en/files/workspace-modules.html#autoreload-for-python-modules\n",
    "# To disable autoreload; run %autoreload 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3c0da8c-dde1-43c1-b85e-ecb422eb375e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F, types as T\n",
    "from dataclasses import dataclass, field\n",
    "from typing import FrozenSet, Tuple\n",
    "from functools import reduce\n",
    "import re\n",
    "from helpers import BRONZE, TAXI_TYPES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6989a27-b16a-4964-bc19-8b929911a5de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77cd5430-51cb-4a48-8a13-9ab8ce6e70b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def to_snake(col_name:str) -> str:\n",
    "    name = re.sub(r'(.)([A-Z][a-z]+)',  r'\\1_\\2', col_name)\n",
    "    name = re.sub(r'([a-z0-9])([A-Z])', r'\\1_\\2', name)\n",
    "    return name.lower()\n",
    "\n",
    "def list_parquet_files(path):\n",
    "    out=[]\n",
    "    for e in dbutils.fs.ls(path):\n",
    "        if e.isDir():  out.extend(list_parquet_files(e.path))\n",
    "        elif e.path.endswith(\".parquet\"): out.append(e.path)\n",
    "    return out\n",
    "\n",
    "def normalize_datetime_cols(df):\n",
    "    mappings = {\n",
    "        \"lpep_pickup_datetime\" : \"tpep_pickup_datetime\",\n",
    "        \"lpep_dropoff_datetime\": \"tpep_dropoff_datetime\",\n",
    "    }\n",
    "    for src, dst in mappings.items():\n",
    "        if src in df.columns and dst not in df.columns:\n",
    "            df = df.withColumnRenamed(src, dst)\n",
    "\n",
    "    return df\n",
    "\n",
    "def load_one(p):\n",
    "    df = spark.read.parquet(p)\n",
    "\n",
    "    for old in df.columns:\n",
    "        new = to_snake(old)\n",
    "        if new != old:\n",
    "            df = df.withColumnRenamed(old, new)\n",
    "\n",
    "    if \"airport_fee\" not in df.columns and \"airportfee\" in df.columns:\n",
    "        df = df.withColumnRenamed(\"airportfee\",\"airport_fee\")\n",
    "\n",
    "    for c in set(BRONZE.COLS_FORCE_DOUBLE).intersection(df.columns):\n",
    "        df = df.withColumn(c, F.col(c).cast(T.DoubleType()))\n",
    "\n",
    "    df = normalize_datetime_cols(df)\n",
    "    \n",
    "    if \"tpep_pickup_datetime\" in df.columns:\n",
    "        df = (df\n",
    "               .withColumn(\"trip_year\",  F.year(\"tpep_pickup_datetime\"))\n",
    "               .withColumn(\"trip_month\", F.month(\"tpep_pickup_datetime\")))\n",
    "    return df\n",
    "\n",
    "def safe_read(path:str):\n",
    "    try:\n",
    "        df = load_one(path)\n",
    "        missing = [c for c in BRONZE.REQUIRED_COLS if c not in df.columns]\n",
    "        if missing:\n",
    "            raise ValueError(f\"faltando cols {missing}\")\n",
    "        return df.withColumn(\"_source_file\", F.input_file_name())\n",
    "    except Exception as e:\n",
    "        print(\"Arquivo em quarentena:\", path.split('/')[-1], \"—\", e)\n",
    "        dbutils.fs.mv(path, f\"{BRONZE.QUARANTINE}/{path.split('/')[-1]}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4040eab1-3e85-4485-b665-53a4d3619fc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf2b8d8b-ecc9-4b3d-9b36-68374d030080",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for tt in TAXI_TYPES:\n",
    "    src_dir = f\"{BRONZE.RAW_ROOT}/taxi_type={tt}\"\n",
    "    files   = list_parquet_files(src_dir)\n",
    "\n",
    "    if not files:\n",
    "        print(f\"Nenhum arquivo para {tt}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Bronze {tt} – {len(files)} arquivos\")\n",
    "\n",
    "    dfs = [safe_read(p) for p in files]\n",
    "    dfs = [d for d in dfs if d is not None]        \n",
    "    if not dfs:\n",
    "        print(f\"todos os arquivos de {tt} caíram na quarentena\")\n",
    "        continue\n",
    "\n",
    "    bronze_df = reduce(\n",
    "        lambda d1, d2: d1.unionByName(d2, allowMissingColumns=True), dfs\n",
    "    )\n",
    "\n",
    "    bronze_df = (\n",
    "        bronze_df\n",
    "        .withColumn(\"ingestion_ts\",  F.current_timestamp())\n",
    "        .withColumn(\"trip_year\",     F.year(\"tpep_pickup_datetime\"))\n",
    "        .withColumn(\"trip_month\",    F.month(\"tpep_pickup_datetime\"))\n",
    "    )\n",
    "\n",
    "    for c in bronze_df.columns:\n",
    "        snake = to_snake(c)\n",
    "        if c != snake:\n",
    "            bronze_df = bronze_df.withColumnRenamed(c, snake)\n",
    "\n",
    "    tbl = f\"{BRONZE.SCHEMA}.{tt}_tripdata_bronze\"\n",
    "\n",
    "    (bronze_df.write\n",
    "        .format(\"delta\")\n",
    "        .mode(\"overwrite\")                  \n",
    "        .partitionBy(\"trip_year\", \"trip_month\")\n",
    "        .option(\"overwriteSchema\", \"true\")\n",
    "        .option(\"delta.feature.checkConstraints\", \"supported\")\n",
    "        .option(\"delta.constraints.total_amount_nonnegative\",\n",
    "                \"total_amount >= 0\")\n",
    "        .option(\"delta.constraints.pickup_before_dropoff\",\n",
    "                \"tpep_pickup_datetime <= tpep_dropoff_datetime\")\n",
    "        .option(\"delta.constraints.valid_year\",  \"trip_year = 2023\")\n",
    "        .option(\"delta.constraints.valid_month\", \"trip_month BETWEEN 1 AND 12\")\n",
    "        .saveAsTable(tbl)\n",
    "    )\n",
    "\n",
    "    print(\"Arquivo gravado —\", spark.table(tbl).count(), \"linhas\")\n",
    "\n",
    "print(\"Camada Bronze concluída\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6965736245755673,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "02_elt_bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
